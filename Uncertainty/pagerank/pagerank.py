import os
import random
import re
import sys

DAMPING = 0.85
SAMPLES = 10000


def main():
    if len(sys.argv) != 2:
        sys.exit("Usage: python pagerank.py corpus")
    corpus = crawl(sys.argv[1])
    ranks = sample_pagerank(corpus, DAMPING, SAMPLES)
    print(f"PageRank Results from Sampling (n = {SAMPLES})")
    for page in sorted(ranks):
        print(f"  {page}: {ranks[page]:.4f}")
    ranks = iterate_pagerank(corpus, DAMPING)
    print(f"PageRank Results from Iteration")
    for page in sorted(ranks):
        print(f"  {page}: {ranks[page]:.4f}")


def crawl(directory):
    """
    Parse a directory of HTML pages and check for links to other pages.
    Return a dictionary where each key is a page, and values are
    a list of all other pages in the corpus that are linked to by the page.
    """
    pages = dict()

    # Extract all links from HTML files
    for filename in os.listdir(directory):
        if not filename.endswith(".html"):
            continue
        with open(os.path.join(directory, filename)) as f:
            contents = f.read()
            links = re.findall(r"<a\s+(?:[^>]*?)href=\"([^\"]*)\"", contents)
            pages[filename] = set(links) - {filename}

    # Only include links to other pages in the corpus
    for filename in pages:
        pages[filename] = set(
            link for link in pages[filename]
            if link in pages
        )

    return pages


def transition_model(corpus, page, damping_factor):
    """
    Return a probability distribution over which page to visit next,
    given a current page.

    With probability `damping_factor`, choose a link at random
    linked to by `page`. With probability `1 - damping_factor`, choose
    a link at random chosen from all pages in the corpus.
    """
    pd_dict = dict()
   
    #print(f"Type of page: {type(page)}, Value of page: {page}")
    non_self_page_count = len(corpus[page])
    #if page has no branches
    if len(corpus[page]) <= 0:
        #return a pd that chooses randomely among all pages with equal probability
        for page in corpus:
            #add equal probability to all pages
            pd_dict[page] = (1 / len(corpus))
            return pd_dict

    #vvvvv rework function for values in corpus[page]
    # for key in corpus:
    #     if key is page:
    #         pd_dict[key] = 0
    #     if key is not page:
    #         #add pages that are not linked to by the current page with a chance of 1-damp/n-1
    #         pd_dict[key] = ((1 - damping_factor) / (page_count - 1))
    #         print(pd_dict[key], "pd_dict[key] after key is not page")
    # #for page in corpus:
    #     #add pages that are linked to by the current page with a chance of damp/n
    #         pd_dict[key] += (damping_factor / (page_count - 1))
    #         print(pd_dict[key], "pd_dict[key] after AFTER key is not page")

    #initialize the dict to have values of 0
    for pages in corpus:
        pd_dict[pages] = 0

    for link in corpus[page]:
        #add pages that are not linked to by the current page with a chance of 1-damp/n-1
        pd_dict[link] += ((1 - damping_factor) / (non_self_page_count))
        #print(pd_dict[link], "pd_dict[key] after key is not page")

        pd_dict[link] += (damping_factor / (non_self_page_count))
        #print(pd_dict[link], "pd_dict[key] after AFTER key is not page")


    # Ensure PageRank values sum to 1
    norm_factor = sum(pd_dict.values())
    if norm_factor > 0:
        for page in pd_dict:
                pd_dict[page] /= norm_factor

    return pd_dict
    #assert that the sum of the probabilities is 1
    #return dict with key as page and value as probability of visiting that page
    #raise NotImplementedError


def sample_pagerank(corpus, damping_factor, n):
    """
    Return PageRank values for each page by sampling `n` pages
    according to transition model, starting with a page at random.

    Return a dictionary where keys are page names, and values are
    their estimated PageRank value (a value between 0 and 1). All
    PageRank values should sum to 1.
    """
    print(n, "n")
    original_n = n
    pr_dict = dict()
    for page in corpus:
        pr_dict[page] = 0
    print(pr_dict, "pr_dict")

    #The first sample should be generated by choosing from a page at random.
    page = random.choice(list(corpus.keys()))
    print(f"Starting page: {page}")


    while n:
        print(f"Sample {n}: Current page: {page}")

        # pass previous sample into your transition_model function,
        # along with the corpus and the damping_factor,
        # to get the probabilities for the next sample
        pd = transition_model(corpus, page, damping_factor)
        print(pd, "pd")

        #add the sample to the pr dict, 1/original_n to keep sum==1
        pr_dict[page] += (1/original_n)

        #pick a random page based on the pd values !!!
        # k=1 ensures only one element is chosen from the list returned by random.choices
        # [0] accesses that single element from the resulting list.
        page = random.choices(list(pd.keys()), list(pd.values()), k=1)[0]
        #print(f"Next page: {page}")

        #decrement n
        n -= 1

    #values in this dictionary should sum to 1.
    #print(pr_dict, "pr_dict")
    #print(sum(pr_dict.values()), "sum of pr values")

    # Ensure PageRank values sum to 1
    norm_factor = sum(pr_dict.values())
    for page in pr_dict:
        pr_dict[page] /= norm_factor
    return pr_dict

def iterate_pagerank(corpus, damping_factor):
    """
    Return PageRank values for each page by iteratively updating
    PageRank values until convergence.

    Return a dictionary where keys are page names, and values are
    their estimated PageRank value (a value between 0 and 1). All
    PageRank values should sum to 1.
    """
    pr_values = dict()
    tolerance = 0.001

    #d is the damping factor,
    d = damping_factor
    # N is the total number of pages in the corpus,
    N = len(corpus)
    # i ranges over all pages that link to page p,
    #i = 0
    # and NumLinks(i) is the number of links present on page i.
    #num_links = NumLinks(i)

    # Initialize PageRank values to 1 / N for all pages
    for page in corpus:
        pr_values[page] = 1 / N
    print(pr_values, "pr_values initialized")

         # Iterate until < 0.001 diff
    while True:
        new_pr_values = {}
         # loop over all pages
        for page in corpus:
            # Calculate the new PageRank value for `page`
            sum_rank = 0
            # Loop over all pages that link to the current page
            for linking_page in corpus:
                # Check if the linking page has a link to the current page
                if page in corpus[linking_page]:
                    # Calculate the sum of the PageRank values of all pages that link
                    sum_rank += pr_values[linking_page] / NumLinks(linking_page, corpus)
            # Update the PageRank value based on the formula
            new_pr_values[page] = (1 - d) / N + d * sum_rank

        # Check for difference
        diff = sum(abs(new_pr_values[page] - pr_values[page]) for page in corpus)
        if diff < tolerance:
            break

        # Update the PageRank values
        pr_values = new_pr_values
        print(pr_values, "updated pr_values")

    # Ensure PageRank values sum to 1
    norm_factor = sum(pr_values.values())
    for page in pr_values:
        pr_values[page] /= norm_factor

    print(pr_values, "final pr_values")
    return pr_values




    # #the sigma part of the equation
    # #range over all pages that link to page p
    # for i in corpus[page]:
    #     sum = 0
    #     sum += (pr_values[i]) / (NumLinks(i, corpus))

    #     print(((1 - d)/(N)) + (d * (sum)), "equation")

    #     pr_values[page] = ((1 - d)/(N)) + (d * (sum))

    #PageRank values should sum to 1.
    print(pr_values, "pr_values!!!!!!!!!!!!!!!!!!!!!!!!!!!")

    #assert sum(pr_values.values()) == 1, "Sum of pr_values is not 1"
    return pr_values

def NumLinks(i, corpus):
    """
    Return the number of links present on page i.
    """
    return len(corpus[i])


if __name__ == "__main__":
    main()
